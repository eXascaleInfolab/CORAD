{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import various libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from pywt import wavedec\n",
    "import pywt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import iqr\n",
    "import sys\n",
    "import copy\n",
    "from scipy.signal import detrend\n",
    "import copy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define various constants that will be used throughout the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FS = 100 #define the sampling rate\n",
    "\n",
    "#define the number of samples of data to compress in each block \n",
    "#NOTE: changing the block length affects the compression scheme for the binary map\n",
    "#changing the block length means that NUM_BITS_RUN_LEN will probably have to be changed too \n",
    "NUM_SAMPLES_BLOCK = 3000 \n",
    "\n",
    "#NOTE: these lengths are hard coded based on a block size of NUM_SAMPLES_BLOCK=30000\n",
    "#COEFF_LENGTHS = {'cA5': 946, 'cD5': 946, 'cD4': 1883, 'cD3': 3757, 'cD2': 7506, 'cD1': 15004}\n",
    "COEFF_LENGTHS = {'cA5': 102, 'cD5': 102, 'cD4': 195, 'cD3': 382, 'cD2': 756, 'cD1': 1504}\n",
    "\n",
    "#number of bits that can be used to represent the run length. a 4 bit number corresponds to \n",
    "#a max value of 2**4-1 = 15 bits, which is equal to 32767. so in other words, if the entire\n",
    "#binary map was all 1 or all 0, NUM_BITS_RUN_LEN=4 means we can represent a run of 32767\n",
    "#consecutive 0's or 1's\n",
    "NUM_BITS_RUN_LEN = 4\n",
    "\n",
    "#don't allow the PRD to be greater than 5%\n",
    "MAX_PRD = 0.4\n",
    "\n",
    "#define the threshold percentage for retaining energy of wavelet coefficients\n",
    "#separate percentage for approximate coefficients and separate for detailed\n",
    "THRESH_PERC_APPROX = 0.999\n",
    "THRESH_PERC_D5 = 0.97\n",
    "THRESH_PERC_D4_D1 = 0.85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to do wavelet decomposition. The wavelet used in this project is bior4.4, with 5 levels of decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wavelet_decomposition(sig):\n",
    "    cA5, cD5, cD4, cD3, cD2, cD1 = wavedec(sig, 'bior4.4', level=5)\n",
    "    coeffs = {'cA5': cA5, 'cD5': cD5, 'cD4': cD4, 'cD3': cD3, 'cD2': cD2, 'cD1': cD1}\n",
    "\n",
    "    #plot stuff\n",
    "    do_plot = False\n",
    "\n",
    "    if do_plot:\n",
    "        print('\\n\\n')\n",
    "        print('Plot of wavelet decomposition for all levels')\n",
    "        plt.subplots(figsize=(16,9))\n",
    "\n",
    "        plt.subplot(6,1,1)\n",
    "        plt.plot(coeffs['cA5'])\n",
    "        plt.title('cA5')\n",
    "\n",
    "        plt.subplot(6,1,2)\n",
    "        plt.plot(coeffs['cD5'])\n",
    "        plt.title('cD5')\n",
    "\n",
    "        plt.subplot(6,1,3)\n",
    "        plt.plot(coeffs['cD4'])\n",
    "        plt.title('cD4')\n",
    "\n",
    "        plt.subplot(6,1,4)\n",
    "        plt.plot(coeffs['cD3'])\n",
    "        plt.title('cD3')\n",
    "\n",
    "        plt.subplot(6,1,5)\n",
    "        plt.plot(coeffs['cD2'])\n",
    "        plt.title('cD2')\n",
    "\n",
    "        plt.subplot(6,1,6)\n",
    "        plt.plot(coeffs['cD1'])\n",
    "        plt.title('cD1')\n",
    "        plt.xlabel('Index')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('figs/wavelet_decomposition.png', dpi=150)\n",
    "        plt.show()\n",
    "\n",
    "    return coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to do wavelet reconstruction, assuming that the wavelet is a bior4.4 with 5 levels of decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wavelet_reconstruction(coeffs, orig_data, CR, do_plot=False):\n",
    "    reconstructed = pywt.waverec([coeffs['cA5'], coeffs['cD5'], coeffs['cD4'], coeffs['cD3'], \n",
    "                                    coeffs['cD2'], coeffs['cD1']], 'bior4.4')\n",
    "\n",
    "\n",
    "    if do_plot:\n",
    "        print('\\n\\n')\n",
    "        print('Plot of original signal through the process of compression and decompression:')\n",
    "        \n",
    "        t = [i/FS for i in range(NUM_SAMPLES_BLOCK)]\n",
    "        plt.subplots(figsize=(16,9))\n",
    "        plt.plot(t, orig_data, label='Original Signal')\n",
    "        plt.plot(t, reconstructed, label='Reconstructed Signal')\n",
    "        plt.title('Compression Ratio: %.1f' % CR)\n",
    "        plt.xlabel('Time (seconds)')\n",
    "        plt.ylabel('Amplitude (mV)')\n",
    "        plt.tight_layout()\n",
    "        plt.legend(loc=1)\n",
    "        axes = plt.gca()\n",
    "        axes.set_xlim((17, 21.5))\n",
    "        plt.savefig('figs/reconstructed.png', dpi=150)\n",
    "        plt.show()\n",
    "\n",
    "    return reconstructed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to threshold the wavelet coefficients to a specified energy. Different levels of decomposition are thresholded at different energy percentages. To threshold the energy, calculate the energy of all the coefficients. Then sort the coefficients from highest to lowest, and calculate the energy as each new coefficient is added. Repeat until the percentage is above the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_energy(coeffs, do_plot=False):\n",
    "    #make a deep copy of coeffs to retain the original version\n",
    "    coeffs_orig = copy.deepcopy(coeffs)\n",
    "\n",
    "    binary_map = {}\n",
    "    nonzero_coeff_count = {}\n",
    "\n",
    "    for key in coeffs.keys():\n",
    "        #sort the absolute value of the coefficients in descending order\n",
    "        tmp_coeffs = np.sort(np.abs(coeffs[key]))[::-1]\n",
    "\n",
    "        #calculate the threshold for retaining some percentage of the energy\n",
    "        if key == 'cA5':\n",
    "            thresh_perc = THRESH_PERC_APPROX\n",
    "        elif key == 'cD5':\n",
    "            thresh_perc = THRESH_PERC_D5\n",
    "        else:\n",
    "            thresh_perc = THRESH_PERC_D4_D1\n",
    "\n",
    "        energy_thresholded = thresh_perc*energy(tmp_coeffs)\n",
    "        energy_tmp = 0\n",
    "        for coeff in tmp_coeffs:\n",
    "            energy_tmp = energy_tmp + coeff**2\n",
    "\n",
    "            if energy_tmp >= energy_thresholded:\n",
    "                threshold = coeff\n",
    "                break\n",
    "\n",
    "        #set any coefficients below the threshold to zero\n",
    "        tmp_coeffs = coeffs[key]\n",
    "        inds_to_zero = np.where((tmp_coeffs < threshold) & (tmp_coeffs > -threshold))[0]\n",
    "        tmp_coeffs[inds_to_zero] = 0\n",
    "\n",
    "        #create the binary map\n",
    "        binary_map_tmp = np.ones(len(coeffs[key])).astype(int)\n",
    "        binary_map_tmp[inds_to_zero] = 0\n",
    "\n",
    "        #update the various dictionaries\n",
    "        coeffs[key] = tmp_coeffs\n",
    "        binary_map[key] = binary_map_tmp\n",
    "        nonzero_coeff_count[key] = len(tmp_coeffs)\n",
    "\n",
    "\n",
    "    if do_plot:\n",
    "        print('\\n\\n')\n",
    "        print('Plot of thresholded vs unthresholded coefficients:')\n",
    "        plt.subplots(figsize=(16,9))\n",
    "\n",
    "        plt.subplot(6,1,1)\n",
    "        plt.plot(coeffs_orig['cA5'], label='Original')\n",
    "        plt.plot(coeffs['cA5'], label='Thresholded')\n",
    "        plt.legend(loc=1)\n",
    "        plt.title('cA5')\n",
    "\n",
    "        plt.subplot(6,1,2)\n",
    "        plt.plot(coeffs_orig['cD5'], label='Original')\n",
    "        plt.plot(coeffs['cD5'], label='Thresholded')\n",
    "        plt.legend(loc=1)\n",
    "        plt.title('cD5')\n",
    "\n",
    "        plt.subplot(6,1,3)\n",
    "        plt.plot(coeffs_orig['cD4'], label='Original')\n",
    "        plt.plot(coeffs['cD4'], label='Thresholded')\n",
    "        plt.legend(loc=1)\n",
    "        plt.title('cD4')\n",
    "\n",
    "        plt.subplot(6,1,4)\n",
    "        plt.plot(coeffs_orig['cD3'], label='Original')\n",
    "        plt.plot(coeffs['cD3'], label='Thresholded')\n",
    "        plt.legend(loc=1)\n",
    "        plt.title('cD3')\n",
    "\n",
    "        plt.subplot(6,1,5)\n",
    "        plt.plot(coeffs_orig['cD2'], label='Original')\n",
    "        plt.plot(coeffs['cD2'], label='Thresholded')\n",
    "        plt.legend(loc=1)\n",
    "        plt.title('cD2')\n",
    "\n",
    "        plt.subplot(6,1,6)\n",
    "        plt.plot(coeffs_orig['cD1'], label='Original')\n",
    "        plt.plot(coeffs['cD1'], label='Thresholded')\n",
    "        plt.legend(loc=1)\n",
    "        plt.xlabel('Index')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('figs/wavelet_thresholding.png', dpi=150)\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "    return coeffs, binary_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to scale the wavelet coefficients to the [0,1] range. This involves two scaling factors: a shift factor and a multiplication factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_coeffs(coeffs, do_plot=False):\n",
    "    coeffs_scaled = {}\n",
    "    scaling_factors = {}\n",
    "\n",
    "    for key in coeffs.keys():\n",
    "        shift_factor = np.min(coeffs[key])\n",
    "        coeffs_tmp = coeffs[key]-shift_factor\n",
    "\n",
    "        scale_factor = np.max(coeffs_tmp)\n",
    "        coeffs_tmp = coeffs_tmp/scale_factor\n",
    "\n",
    "        scaling_factors[key] = {'shift_factor': shift_factor, 'scale_factor': scale_factor}\n",
    "        coeffs_scaled[key] = coeffs_tmp\n",
    "\n",
    "\n",
    "    if do_plot:\n",
    "        print('\\n\\n')\n",
    "        print('Plot of scaled coefficients:')\n",
    "        plt.subplots(figsize=(16,9))\n",
    "\n",
    "        plt.subplot(6,1,1)\n",
    "        plt.plot(coeffs_scaled['cA5'])\n",
    "        plt.title('cA5')\n",
    "\n",
    "        plt.subplot(6,1,2)\n",
    "        plt.plot(coeffs_scaled['cD5'])\n",
    "        plt.title('cD5')\n",
    "\n",
    "        plt.subplot(6,1,3)\n",
    "        plt.plot(coeffs_scaled['cD4'])\n",
    "        plt.title('cD4')\n",
    "\n",
    "        plt.subplot(6,1,4)\n",
    "        plt.plot(coeffs_scaled['cD3'])\n",
    "        plt.title('cD3')\n",
    "\n",
    "        plt.subplot(6,1,5)\n",
    "        plt.plot(coeffs_scaled['cD2'])\n",
    "        plt.title('cD2')\n",
    "\n",
    "        plt.subplot(6,1,6)\n",
    "        plt.plot(coeffs_scaled['cD1'])\n",
    "        plt.title('cD1')\n",
    "        plt.xlabel('Index')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('figs/wavelet_scaled.png', dpi=150)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    return coeffs_scaled, scaling_factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to unscale the coefficients back to their original scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unscale_coeffs(coeffs_orig, coeffs_reconstructed, scaling_factors, bits, do_plot=False):\n",
    "    coeffs_unscaled = {}\n",
    "\n",
    "    for key in coeffs_reconstructed.keys():\n",
    "        tmp_coeffs_unscaled = coeffs_reconstructed[key]/(2**bits)\n",
    "        tmp_coeffs_unscaled = tmp_coeffs_unscaled*scaling_factors[key]['scale_factor']\n",
    "        tmp_coeffs_unscaled = tmp_coeffs_unscaled + scaling_factors[key]['shift_factor']\n",
    "\n",
    "        #now replace the NaN values with 0\n",
    "        nan_inds = np.where(np.isnan(tmp_coeffs_unscaled))[0]\n",
    "        tmp_coeffs_unscaled[nan_inds] = 0\n",
    "\n",
    "        coeffs_unscaled[key] = tmp_coeffs_unscaled\n",
    "\n",
    "\n",
    "    if do_plot:\n",
    "        print('\\n\\n')\n",
    "        print('Plot of wavelet coefficients before scaling and after rescaling:')\n",
    "        plt.subplots(figsize=(16,9))\n",
    "\n",
    "        plt.subplot(6,1,1)\n",
    "        plt.plot(coeffs_orig['cA5'], label='Before Scaling')\n",
    "        plt.plot(coeffs_unscaled['cA5'], label='After Rescaling')\n",
    "        plt.legend(loc=1)\n",
    "        plt.title('cA5')\n",
    "\n",
    "        plt.subplot(6,1,2)\n",
    "        plt.plot(coeffs_orig['cD5'], label='Before Scaling')\n",
    "        plt.plot(coeffs_unscaled['cD5'], label='After Rescaling')\n",
    "        plt.legend(loc=1)\n",
    "        plt.title('cD5')\n",
    "\n",
    "        plt.subplot(6,1,3)\n",
    "        plt.plot(coeffs_orig['cD4'], label='Before Scaling')\n",
    "        plt.plot(coeffs_unscaled['cD4'], label='After Rescaling')\n",
    "        plt.legend(loc=1)\n",
    "        plt.title('cD4')\n",
    "\n",
    "        plt.subplot(6,1,4)\n",
    "        plt.plot(coeffs_orig['cD3'], label='Before Scaling')\n",
    "        plt.plot(coeffs_unscaled['cD3'], label='After Rescaling')\n",
    "        plt.legend(loc=1)\n",
    "        plt.title('cD3')\n",
    "\n",
    "        plt.subplot(6,1,5)\n",
    "        plt.plot(coeffs_orig['cD2'], label='Before Scaling')\n",
    "        plt.plot(coeffs_unscaled['cD2'], label='After Rescaling')\n",
    "        plt.legend(loc=1)\n",
    "        plt.title('cD2')\n",
    "\n",
    "        plt.subplot(6,1,6)\n",
    "        plt.plot(coeffs_orig['cD1'], label='Before Scaling')\n",
    "        plt.plot(coeffs_unscaled['cD1'], label='After Rescaling')\n",
    "        plt.legend(loc=1)\n",
    "        plt.xlabel('Index')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('figs/wavelet_rescaled.png', dpi=150)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    return coeffs_unscaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to calculate the lowest possible number of bits to quantize the wavelet coefficients such that the PRD is above the threshold. To do this, first quantize the signal starting at 8 bits, then unquantize and reconstruct the signal, and then calculate the PRD. Repeat with 1 fewer bit (ie, 7 bits), and so on..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_num_bits(orig_sig, coeffs_scaled, binary_map, scaling_factors, do_plot=False):\n",
    "    #starting at 8 bits, keep decreasing the number of bits in the quantization\n",
    "    #until the PRD is above some threshold\n",
    "    num_bits = 9\n",
    "\n",
    "    \n",
    "    #initialize PRD to 0 so the while loop can run\n",
    "    PRD = 0\n",
    "    \n",
    "    MSE = 0\n",
    "\n",
    "    #keep track of PRD per number of bits\n",
    "    PRD_dict = {}\n",
    "\n",
    "    if do_plot:\n",
    "        plt.subplots(figsize=(16,9))\n",
    "        t = [i/FS for i in range(NUM_SAMPLES_BLOCK)]\n",
    "        plt.plot(t, orig_sig, label='Original Signal')\n",
    "\n",
    "\n",
    "    while (num_bits >= 5) and (PRD <= MAX_PRD):\n",
    "        #decrement the number of bits\n",
    "        num_bits = num_bits-1\n",
    "\n",
    "        coeffs_quantized = do_quantization(coeffs_scaled, num_bits)\n",
    "\n",
    "        #rescale the coefficients\n",
    "        coeffs_unscaled = unscale_coeffs(None, coeffs_quantized, scaling_factors, num_bits)\n",
    "\n",
    "        #do the inverse dwt\n",
    "        data_reconstructed = wavelet_reconstruction(coeffs_unscaled, None, None)\n",
    "\n",
    "        #calculate PRD\n",
    "        PRD = calculate_PRD(orig_sig, data_reconstructed)\n",
    "        MSE = calculate_MSE(orig_sig, data_reconstructed)\n",
    "        PRD_dict[num_bits] = PRD\n",
    "\n",
    "        #plot the reconstructed signals \n",
    "        if do_plot:\n",
    "            if PRD <= MAX_PRD:\n",
    "                plt.plot(t, data_reconstructed, label='Reconstructed @ %i Bits, PRD = %.2f' % (num_bits, PRD))\n",
    "\n",
    "    #if we went over the PRD, go back up by one bit\n",
    "    if PRD > MAX_PRD:\n",
    "        num_bits = num_bits+1\n",
    "        PRD = PRD_dict[num_bits]\n",
    "\n",
    "    #plot some more stuff\n",
    "    if do_plot:\n",
    "        print('\\n\\n')\n",
    "        print('Plots of reconstructed signals vs number of bits used for quantization:')\n",
    "        plt.legend(loc=1)\n",
    "        plt.tight_layout()\n",
    "        plt.xlabel('Time (seconds)')\n",
    "        plt.ylabel('Amplitude (mV)')\n",
    "        axes = plt.gca()\n",
    "        axes.set_xlim((17, 21.5))\n",
    "        plt.savefig('figs/PRD.png', dpi=150)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    return num_bits, PRD, MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to combine all the wavelet coefficients (and the binary map) in different decomposition levels into one continuous array. This step is a necessary prerequisite for compression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_coefficients(coeffs, binary_map=None):\n",
    "    coeffs_combined = []\n",
    "\n",
    "    #loop through each of the wavelet decompositions and remove zero values based \n",
    "    #on the binary map\n",
    "    if binary_map is not None:\n",
    "        for key in coeffs.keys():\n",
    "            inds_to_keep = np.where(binary_map[key]==1)[0]\n",
    "            coeffs[key] = coeffs[key][inds_to_keep]\n",
    "\n",
    "    #add in each array to coeffs_combined\n",
    "    coeffs_combined.extend(coeffs['cA5'])\n",
    "    coeffs_combined.extend(coeffs['cD5'])\n",
    "    coeffs_combined.extend(coeffs['cD4'])\n",
    "    coeffs_combined.extend(coeffs['cD3'])\n",
    "    coeffs_combined.extend(coeffs['cD2'])\n",
    "    coeffs_combined.extend(coeffs['cD1'])\n",
    "\n",
    "    return coeffs_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to map the wavelet coefficients (and the binary map) back to their original decomposition levels. This step is a necessary prerequisite for reconstruction of the time domain waveform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remap_coeffs(coeffs, binary_map):\n",
    "    coeffs_remapped = np.zeros(len(binary_map))*np.nan\n",
    "    inds_to_set = np.where(binary_map==1)[0]\n",
    "    coeffs_remapped[inds_to_set] = coeffs\n",
    "\n",
    "    wavelet_remapped = {}\n",
    "    counter = 0\n",
    "    wavelet_remapped['cA5'] = coeffs_remapped[counter:counter+COEFF_LENGTHS['cA5']]\n",
    "\n",
    "    counter = counter + COEFF_LENGTHS['cA5']\n",
    "    wavelet_remapped['cD5'] = coeffs_remapped[counter:counter+COEFF_LENGTHS['cD5']]\n",
    "\n",
    "    counter = counter + COEFF_LENGTHS['cD5']\n",
    "    wavelet_remapped['cD4'] = coeffs_remapped[counter:counter+COEFF_LENGTHS['cD4']]\n",
    "\n",
    "    counter = counter + COEFF_LENGTHS['cD4']\n",
    "    wavelet_remapped['cD3'] = coeffs_remapped[counter:counter+COEFF_LENGTHS['cD3']]\n",
    "\n",
    "    counter = counter + COEFF_LENGTHS['cD3']\n",
    "    wavelet_remapped['cD2'] = coeffs_remapped[counter:counter+COEFF_LENGTHS['cD2']]\n",
    "\n",
    "    counter = counter + COEFF_LENGTHS['cD2']\n",
    "    wavelet_remapped['cD1'] = coeffs_remapped[counter:counter+COEFF_LENGTHS['cD1']]\n",
    "\n",
    "    return wavelet_remapped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to do quantization. This function takes in the scaled wavelet coefficients and then multiplies by 2^(num bits), and then rounds to the nearest integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_quantization(coeffs, bits, do_plot=False):\n",
    "    quantized_coeffs = {}\n",
    "\n",
    "    for key in coeffs.keys():\n",
    "        sig = coeffs[key]\n",
    "        sig = sig*(2**bits-1)\n",
    "        sig = np.round(sig)\n",
    "        sig = np.array(sig).astype(int)\n",
    "\n",
    "        quantized_coeffs[key] = sig\n",
    "\n",
    "\n",
    "    if do_plot:\n",
    "        print('\\n\\n')\n",
    "        print('Plot of quantized coefficients:')\n",
    "        plt.subplots(figsize=(16,9))\n",
    "\n",
    "        plt.subplot(6,1,1)\n",
    "        plt.plot(quantized_coeffs['cA5'])\n",
    "        plt.title('cA5')\n",
    "\n",
    "        plt.subplot(6,1,2)\n",
    "        plt.plot(quantized_coeffs['cD5'])\n",
    "        plt.title('cD5')\n",
    "\n",
    "        plt.subplot(6,1,3)\n",
    "        plt.plot(quantized_coeffs['cD4'])\n",
    "        plt.title('cD4')\n",
    "\n",
    "        plt.subplot(6,1,4)\n",
    "        plt.plot(quantized_coeffs['cD3'])\n",
    "        plt.title('cD3')\n",
    "\n",
    "        plt.subplot(6,1,5)\n",
    "        plt.plot(quantized_coeffs['cD2'])\n",
    "        plt.title('cD2')\n",
    "\n",
    "        plt.subplot(6,1,6)\n",
    "        plt.plot(quantized_coeffs['cD1'])\n",
    "        plt.title('cD1')\n",
    "        plt.xlabel('Index')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('figs/wavelet_quantized.png', dpi=150)\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "    return quantized_coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to compress the wavelet coefficients. The process is quite simply combining bits together into bytes. More details on the encoding scheme is defined in the readme file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_coefficients(coeffs, num_bits):\n",
    "\n",
    "    binary_string = ''\n",
    "\n",
    "    for coeff in coeffs:\n",
    "        #convert each coefficient value to binary in num_bits number of bits\n",
    "        binary_string = binary_string + format(coeff, '0%ib' % num_bits)\n",
    "\n",
    "    #loop through sets of 8 bits in the binary string and convert to a byte\n",
    "    byte_array = []\n",
    "    for i in range(int(len(binary_string)/8)):\n",
    "        byte_tmp = binary_string[i*8:(i+1)*8]\n",
    "        byte_tmp = int(byte_tmp, 2)\n",
    "        byte_array.append(byte_tmp)\n",
    "\n",
    "    #check if there are any remaining bits that don't divide evenly into 8\n",
    "    #note the number of bits in this last byte for conversion back to int\n",
    "    #later on\n",
    "    num_bits_last_byte = 8\n",
    "    if len(binary_string)%8 != 0:\n",
    "        byte_tmp = binary_string[(i+1)*8:(i+1)*8 + len(binary_string)%8]\n",
    "        num_bits_last_byte = len(byte_tmp)\n",
    "        byte_tmp = int(byte_tmp, 2)\n",
    "        byte_array.append(byte_tmp)\n",
    "\n",
    "    return byte_array, num_bits_last_byte\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to decompress the previously compressed wavelet coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompress_coefficients(coeffs_compressed, num_bits, num_bits_last_byte):\n",
    "\n",
    "    binary_string = ''\n",
    "\n",
    "    #convert each coefficient value to binary in 8 number of bits\n",
    "    #note that the very last value in the the binary map may not be\n",
    "    #a full 8 bits. so convert that based on num_bits_last_byte\n",
    "    coeffs_len = len(coeffs_compressed)\n",
    "    for i in range(coeffs_len):\n",
    "        if i == coeffs_len-1:\n",
    "            binary_string = binary_string + format(coeffs_compressed[i], '0%ib' % num_bits_last_byte)\n",
    "        else:\n",
    "            binary_string = binary_string + format(coeffs_compressed[i], '08b')\n",
    "\n",
    "\n",
    "    #loop through sets of num_bits bits in the binary string and convert to a byte\n",
    "    byte_array = []\n",
    "    for i in range(int(len(binary_string)/num_bits)):\n",
    "        byte_tmp = binary_string[i*num_bits:(i+1)*num_bits]\n",
    "        byte_tmp = int(byte_tmp, 2)\n",
    "        byte_array.append(byte_tmp)\n",
    "\n",
    "\n",
    "    return byte_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to compress the binary map using variable length run-length encoding (RLE). The specifics of the encoding scheme is defined in the readme file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_binary_map(binary_map):\n",
    "    #define a state machine that loops through each entry in the binary map and \n",
    "    #creates the compressed representation. \n",
    "\n",
    "    #the last run count won't be included in the compressed representation, so \n",
    "    #just append one more value at the end of the binary map to trigger the last \n",
    "    #compression value. make a local deep copy so that the original is not affected\n",
    "    binary_map = copy.deepcopy(binary_map)\n",
    "    binary_map.append(int(not binary_map[-1]))\n",
    "\n",
    "\n",
    "    CURRENT_STATE = binary_map[0]\n",
    "    run_count = 0\n",
    "    binary_string = ''\n",
    "\n",
    "    #loop through each value in the binary map\n",
    "    for val in binary_map:\n",
    "\n",
    "        #if the current binary map value is the same as the previous one, just increment the run count\n",
    "        if val == CURRENT_STATE:\n",
    "            run_count = run_count + 1\n",
    "\n",
    "        #otherwise, encode the current run count \n",
    "        else:\n",
    "\n",
    "            #handle cases where run count <= 3\n",
    "            if run_count == 1:\n",
    "                binary_string_tmp = '00'\n",
    "\n",
    "            elif run_count == 2:\n",
    "                binary_string_tmp = '01'\n",
    "\n",
    "            elif run_count == 3:\n",
    "                binary_string_tmp = '10'\n",
    "\n",
    "            #otherwise, if the run count > 3\n",
    "            else:\n",
    "                #calculate the number bits required to represent the run count\n",
    "                num_bits_run_count = len(format(run_count, 'b'))\n",
    "\n",
    "                #build a binary string\n",
    "                binary_string_tmp = ''\n",
    "\n",
    "                #first bit represents that the run count > 3\n",
    "                binary_string_tmp = binary_string_tmp + '11'\n",
    "\n",
    "                #next 4 bits represent the number of bits that will define the run count\n",
    "                binary_string_tmp = binary_string_tmp + format(num_bits_run_count, '0%ib' % NUM_BITS_RUN_LEN)\n",
    "\n",
    "                #next number of bits is variable, and is the actual run count\n",
    "                #may be up to 15 bits assuming NUM_BITS_RUN_LEN=4\n",
    "                binary_string_tmp = binary_string_tmp + format(run_count, 'b')\n",
    "\n",
    "            #print(str(run_count) + ', ' + binary_string_tmp)\n",
    "            #pdb.set_trace()\n",
    "\n",
    "            #append the binary string\n",
    "            binary_string = binary_string + binary_string_tmp\n",
    "\n",
    "            #reset the run count \n",
    "            run_count = 1\n",
    "\n",
    "        #update the current state\n",
    "        CURRENT_STATE = val\n",
    "\n",
    "\n",
    "    #convert the binary string into a buffer of 8 bit bytes \n",
    "    byte_array = []\n",
    "    for i in range(int(len(binary_string)/8)):\n",
    "        byte_tmp = binary_string[i*8:(i+1)*8]\n",
    "        byte_tmp = int(byte_tmp, 2)\n",
    "        byte_array.append(byte_tmp)\n",
    "\n",
    "\n",
    "    #check if there are any remaining bits that don't divide evenly into 8\n",
    "    num_bits_last_byte = 8\n",
    "    if len(binary_string)%8 != 0:\n",
    "        byte_tmp = binary_string[(i+1)*8:(i+1)*8 + len(binary_string)%8]\n",
    "        num_bits_last_byte = len(byte_tmp)\n",
    "        byte_tmp = int(byte_tmp, 2)\n",
    "        byte_array.append(byte_tmp)\n",
    "\n",
    "\n",
    "    #return the initial state (ie, the first value in binary map), and the RLE binary map\n",
    "    return binary_map[0], byte_array, num_bits_last_byte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to decompress the previously compressed binary map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompress_binary_map(binary_map_compressed, binary_map_initial_state, num_bits_last_byte):\n",
    "\n",
    "    #first convert 8 bit numbers into a binary string\n",
    "    binary_string = ''\n",
    "\n",
    "    #convert each coefficient value to binary in 8 number of bits\n",
    "    #note that the very last value in the the binary map may not be\n",
    "    #a full 8 bits. so convert that based on num_bits_last_byte\n",
    "    binary_map_len = len(binary_map_compressed)\n",
    "    for i in range(binary_map_len):\n",
    "        if i == binary_map_len-1:\n",
    "            binary_string = binary_string + format(binary_map_compressed[i], '0%ib' % num_bits_last_byte)\n",
    "        else:\n",
    "            binary_string = binary_string + format(binary_map_compressed[i], '08b')\n",
    "\n",
    "\n",
    "    #define a state machine that loops through each entry in the binary map and \n",
    "    #creates the uncompressed representation. \n",
    "    READ_HEADER = 0\n",
    "    READ_NUM_BITS = 1\n",
    "    READ_RUN_LEN = 2\n",
    "    state = READ_HEADER\n",
    "\n",
    "    run_type = binary_map_initial_state\n",
    "    header = ''\n",
    "    binary_array = np.array([])\n",
    "\n",
    "\n",
    "    #loop through each value in the binary map\n",
    "    for val in binary_string:\n",
    "\n",
    "        #read the header\n",
    "        if state == READ_HEADER:\n",
    "            header = header + val\n",
    "\n",
    "            if len(header) == 2:\n",
    "                #run count 1\n",
    "                if header == '00':\n",
    "                    binary_array = np.concatenate((binary_array, np.ones(1)*run_type))\n",
    "                    run_type = int(not run_type)\n",
    "                    state = READ_HEADER\n",
    "\n",
    "                #run count 2\n",
    "                if header == '01':\n",
    "                    binary_array = np.concatenate((binary_array, np.ones(2)*run_type))\n",
    "                    run_type = int(not run_type)\n",
    "                    state = READ_HEADER\n",
    "\n",
    "                #run count 3\n",
    "                if header == '10':\n",
    "                    binary_array = np.concatenate((binary_array, np.ones(3)*run_type))\n",
    "                    run_type = int(not run_type)\n",
    "                    state = READ_HEADER\n",
    "\n",
    "                #run count > 3\n",
    "                if header == '11':\n",
    "                    state = READ_NUM_BITS\n",
    "                    num_bits = ''\n",
    "\n",
    "\n",
    "                #reset header \n",
    "                header = ''\n",
    "\n",
    "            continue\n",
    "\n",
    "        #read number of bits\n",
    "        if state == READ_NUM_BITS:\n",
    "\n",
    "\n",
    "            num_bits = num_bits + val\n",
    "\n",
    "            if len(num_bits) == 4:\n",
    "                num_bits_run_len = int(num_bits, 2)\n",
    "                run_len = ''\n",
    "\n",
    "                state = READ_RUN_LEN\n",
    "\n",
    "            continue\n",
    "\n",
    "\n",
    "        #read run length\n",
    "        if state == READ_RUN_LEN:\n",
    "            run_len = run_len + val\n",
    "\n",
    "            if len(run_len) == num_bits_run_len:\n",
    "                run_len = int(run_len, 2)\n",
    "                binary_array = np.concatenate((binary_array, np.ones(run_len)*run_type))\n",
    "                run_type = int(not run_type)\n",
    "                state = READ_HEADER\n",
    "\n",
    "            continue\n",
    "\n",
    "\n",
    "    return binary_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to calculate the compression ratio. This assumes a float requires 32 bits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_compression_ratio(coeffs_compressed, scaling_factors, num_bits, binary_map_compressed, binary_map_initial_state):\n",
    "\n",
    "    #each value in the compressed coefficients is 8 bits\n",
    "    num_bits_compressed = len(coeffs_compressed)*8\n",
    "\n",
    "    #the number of bits in the last byte of the compressed coeffs is 8\n",
    "    #and another 8 bits for the last byte of the compressed binary map\n",
    "    num_bits_compressed = num_bits_compressed + 16\n",
    "\n",
    "    #each set of scaling factors has 2 float values, and each float value is 32 bits\n",
    "    num_bits_compressed = num_bits_compressed + len(scaling_factors)*2*32\n",
    "\n",
    "    #the number of bits corresponds to one byte\n",
    "    num_bits_compressed = num_bits_compressed + 8\n",
    "\n",
    "    #each value in the compressed binary map is 8 bits\n",
    "    num_bits_compressed = num_bits_compressed + len(binary_map_compressed)*8\n",
    "\n",
    "    #the initial state of the binary map is just one bit but assume it's stored as a byte\n",
    "    num_bits_compressed = num_bits_compressed + 8\n",
    "\n",
    "    #each of the original data are 16 bits \n",
    "    num_bits_uncompressed = NUM_SAMPLES_BLOCK*16\n",
    "\n",
    "    #get the compression ratio\n",
    "    compression_ratio = num_bits_uncompressed/num_bits_compressed\n",
    "\n",
    "    return compression_ratio   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to detrend the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_detrend(sig, do_plot=False):\n",
    "    detrended = detrend(sig)\n",
    "\n",
    "    if do_plot:\n",
    "        print('\\n\\n')\n",
    "        print('Original and detrended signal:')\n",
    "        \n",
    "        t = [i/FS for i in range(NUM_SAMPLES_BLOCK)]\n",
    "        plt.subplots(figsize=(16,9))\n",
    "        plt.plot(t, sig, label='Original Signal')\n",
    "        plt.plot(t, detrended, label='Detrended Signal')\n",
    "        plt.xlabel('Time (seconds)')\n",
    "        plt.ylabel('Amplitude (mV)')\n",
    "        plt.tight_layout()\n",
    "        plt.legend(loc=1)\n",
    "        axes = plt.gca()\n",
    "        axes.set_xlim((17, 21.5))\n",
    "        plt.savefig('figs/detrending.png', dpi=150)\n",
    "        plt.show()\n",
    "\n",
    "    return detrended"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to calculate signal energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def energy(sig):\n",
    "    return np.sum(sig**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to calculate the percentage root-mean-square difference (PRD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized(ts):\n",
    "    # pop = np.array([np.array(xi) for xi in ts])\n",
    "    # return (pop - np.min(pop)) / (np.max(pop) - np.min(pop))\n",
    "    from scipy import stats\n",
    "    return stats.zscore(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_PRD(orig_sig, reconstructed_sig):\n",
    "    orig_sig = normalized(orig_sig)\n",
    "    reconstructed_sig = normalized(reconstructed_sig)\n",
    "    \n",
    "    num = np.sum((orig_sig - reconstructed_sig)**2)\n",
    "    den = np.sum(orig_sig**2)\n",
    "    \n",
    "\n",
    "    PRD = np.sqrt(num/den)\n",
    "\n",
    "    return PRD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And another for root mean square error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_MSE(t1, t2):\n",
    "    return (np.square(t1 - t2)).mean(axis=None)\n",
    "    #print((np.square(t1 - t2)).mean(axis=None) == ((t1 - t2)**2).mean(axis=None))\n",
    "  # return ((t1 - t2)**2).mean(axis=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main function...putting everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99999, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:38: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/indexing.py:947: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  return getattr(section, self.name)[new_key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average compression ratio: 11.0\n",
      "Average PRD: 0.242\n",
      "Average MSE: 0.061\n",
      "Compression time 7.004\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "df = pd.read_pickle('Gas-2.pkl')\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "from scipy import stats\n",
    "df = pd.DataFrame(stats.zscore(df))\n",
    "\n",
    "#calculate the number of 10 second non-overlapping blocks of data\n",
    "N = int(len(df)/NUM_SAMPLES_BLOCK)\n",
    "\n",
    "#calculate the average CR and average PRD and average MSE\n",
    "CR_avg = 0\n",
    "PRD_avg = 0\n",
    "MSE_avg = 0\n",
    "\n",
    "#plot stuff\n",
    "plot = False\n",
    "\n",
    "whole_ts = np.array([])\n",
    "\n",
    "\n",
    "#print(df.info)\n",
    "#df = df.iloc[:,0:4]\n",
    "#print(df.info(verbose=False))\n",
    "\n",
    "#print(df.info)\n",
    "\n",
    "#print(df)\n",
    "import time \n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for i_ts in range(len(df.columns)):\n",
    "    #loop over the data in 10 second chunks\n",
    "    for i in range(N):\n",
    "        #print('hello')\n",
    "        data = df.ix[i*NUM_SAMPLES_BLOCK:(i+1)*NUM_SAMPLES_BLOCK-1, i_ts].values\n",
    "        #print(data)\n",
    "        #detrend the signal as a preprocessing step to remove unecessary information\n",
    "        #data = do_detrend(data, False)\n",
    "        #print(data)\n",
    "        #do wavelet decomposition \n",
    "        coeffs = wavelet_decomposition(data)\n",
    "\n",
    "        #threshold the coefficients such that 95% of the signal energy is retained\n",
    "        #return nonzero thresholded coefficients, along with a binary map of zero/nonzero values\n",
    "        #and a list of how many nonzero values were in each set of coefficients\n",
    "        coeffs_thresholded, binary_map = threshold_energy(coeffs, do_plot=plot)\n",
    "\n",
    "        #scale each set of wavelet coefficients between zero and one \n",
    "        #keep track of the scaling factors to re-scale to the original range later\n",
    "        coeffs_scaled, scaling_factors = scale_coeffs(coeffs_thresholded, do_plot=plot)\n",
    "\n",
    "        #quantize the coefficients. choose the number of bits to quantize based on the PRD\n",
    "        num_bits, PRD_tmp, MSE_tmp = calculate_num_bits(data, coeffs_scaled, binary_map, scaling_factors, do_plot=plot)\n",
    "        PRD_avg = PRD_avg + PRD_tmp\n",
    "        MSE_avg = MSE_avg + MSE_tmp\n",
    "\n",
    "        #get quantized coefficients\n",
    "        coeffs_quantized = do_quantization(coeffs_scaled, num_bits, do_plot=plot)\n",
    "\n",
    "        #combine all the quantized coefficients into a single array for compression\n",
    "        #also combine all the binary maps into a single array for compression\n",
    "        coeffs_quantized_combined = combine_coefficients(coeffs_quantized, binary_map)\n",
    "        binary_map_combined = combine_coefficients(binary_map)\n",
    "\n",
    "        #compress the quantized coefficients\n",
    "        coeffs_quantized_compressed, num_bits_last_byte_coeffs = compress_coefficients(coeffs_quantized_combined, num_bits)\n",
    "\n",
    "        #compress the binary map\n",
    "        binary_map_initial_state, binary_map_compressed, num_bits_last_byte_binary_map = compress_binary_map(binary_map_combined)\n",
    "\n",
    "        #\"transmit\" all the necessary information to reconstruct the signal on the recieving end\n",
    "        #this includes:\n",
    "        #1. the compressed coefficients\n",
    "        #2. the number of bits associated with the last byte of the compressed coefficients\n",
    "        #3. the scaling factors for each wavelet decomposition\n",
    "        #4. the number of bits used to quantize the coefficients\n",
    "        #5. the compressed binary map\n",
    "        #6. the number of bits associated with the last byte of the compressed binary map\n",
    "        #7. the initial state of the binary map\n",
    "\n",
    "        #calculate the compression ratio for this transmission\n",
    "        CR_tmp = calculate_compression_ratio(coeffs_quantized_compressed, scaling_factors, num_bits, binary_map_compressed, binary_map_initial_state)\n",
    "        CR_avg = CR_avg + CR_tmp\n",
    "\n",
    "        #decompress the binary map\n",
    "        binary_map_decompressed = decompress_binary_map(binary_map_compressed, binary_map_initial_state, num_bits_last_byte_binary_map)\n",
    "\n",
    "        #decompress the coefficients\n",
    "        coeffs_decompressed = decompress_coefficients(coeffs_quantized_compressed, num_bits, num_bits_last_byte_coeffs)\n",
    "\n",
    "        #remap all the coefficients back to their original wavelet decompositions\n",
    "        coeffs_reconstructed = remap_coeffs(coeffs_decompressed, binary_map_decompressed)\n",
    "\n",
    "        #rescale the coefficients\n",
    "        coeffs_unscaled = unscale_coeffs(coeffs, coeffs_reconstructed, scaling_factors, num_bits, do_plot=plot)\n",
    "\n",
    "        #do the inverse dwt\n",
    "        data_reconstructed = wavelet_reconstruction(coeffs_unscaled, data, CR_tmp, do_plot=plot)\n",
    "        #print(calculate_PRD(data, data_reconstructed), PRD_tmp)\n",
    "\n",
    "        #whole_ts = np.concatenate([whole_ts,data_reconstructed])\n",
    "\n",
    "        \n",
    "end = time.time()\n",
    "\n",
    "#calculate the average compression ratio and PRD\n",
    "CR_avg = CR_avg/(N*len(df.columns))\n",
    "PRD_avg = PRD_avg/(N*len(df.columns))\n",
    "MSE_avg = MSE_avg/(N*len(df.columns))\n",
    "print('Average compression ratio: %.1f' % CR_avg)\n",
    "print('Average PRD: %.3f' % PRD_avg)\n",
    "print('Average MSE: %.3f' % MSE_avg)\n",
    "print('Compression time %.3f' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0         1         2         3         4         5         6  \\\n",
      "0     -0.499115 -0.524805 -0.392320 -0.357611 -0.766759 -0.760042 -0.605148   \n",
      "1     -0.513661 -0.107374  0.310171  0.673725  0.133452  0.209911  0.421245   \n",
      "2     -0.523359  0.838913  1.410489  1.737370  0.789798  1.249300  1.665282   \n",
      "3     -0.527515  1.829580  2.126033  2.194795  0.932516  1.799023  2.161126   \n",
      "4     -0.530978  2.356175  2.424390  2.332710  1.076545  1.847928  2.288743   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "99994  1.882988 -0.626162 -0.604949 -0.718616 -1.254306 -1.142785 -1.021705   \n",
      "99995  1.882988 -0.626117 -0.604900 -0.718556 -1.254251 -1.142727 -1.021685   \n",
      "99996  1.883680 -0.626072 -0.604864 -0.718515 -1.254204 -1.142686 -1.021657   \n",
      "99997  1.884373 -0.626032 -0.604831 -0.718474 -1.254141 -1.142654 -1.021637   \n",
      "99998  1.882988 -0.625993 -0.604794 -0.718436 -1.254102 -1.145602 -1.024013   \n",
      "\n",
      "              7         8         9        10        11        12        13  \\\n",
      "0     -0.586478 -0.116791 -0.212519  0.015258  0.262791  0.689707  0.729374   \n",
      "1      0.549350  1.501431  0.908943  1.806721  1.455180  2.012501  1.766139   \n",
      "2      1.547390  2.057003  1.271313  2.254135  2.154297  2.611180  1.930441   \n",
      "3      2.012691  2.246767  1.476321  2.364507  1.903380  1.568044  2.089893   \n",
      "4      2.038871  1.984667  1.449018  2.201378  2.209072  2.406349  1.930441   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "99994 -1.116174 -1.391666 -1.372057 -1.278459 -1.377713 -1.372089 -1.311482   \n",
      "99995 -1.116131 -1.391666 -1.372057 -1.278453 -1.377718 -1.372101 -1.311482   \n",
      "99996 -1.116096 -1.391666 -1.372043 -1.278459 -1.377713 -1.372101 -1.311475   \n",
      "99997 -1.116068 -1.391649 -1.372043 -1.278459 -1.377729 -1.372107 -1.311475   \n",
      "99998 -1.117042 -1.391649 -1.372064 -1.278453 -1.377729 -1.375503 -1.311953   \n",
      "\n",
      "             14  \n",
      "0      0.759951  \n",
      "1      1.799716  \n",
      "2      1.893309  \n",
      "3      1.992613  \n",
      "4      1.820510  \n",
      "...         ...  \n",
      "99994 -1.307426  \n",
      "99995 -1.307426  \n",
      "99996 -1.307426  \n",
      "99997 -1.307426  \n",
      "99998 -1.307614  \n",
      "\n",
      "[99999 rows x 15 columns]\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "#print((df))\n",
    "#print(whole_ts)\n",
    "print(df)\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
