
Title: "Sprintz: Time Series Compression for the Internet of Things"

Davis Blalock, Sam Madden, John Guttag


Overall story / intro:
    -multivariate time series are a ubiquitous form of data, and only growing
    in importance
    -you really want to compress them well to save storage space and
    network bandwidth
    -(?) you also want to be able to compress them using low-power hardware
    in order to support databases that leverage edge/fog computing and/or
    to offload compression to the client
        // ^ these don't seem like rock-solid use cases, but I really want
        something like this to be part of the story because memory requirements
        are where we're 100x better than everything else
    -we introduce the best time series compression algorithm, as measured by
    ratio, decompression speed, and memory requirements
        -(?) our decompression speed is fast enough that you can just leave
        the data compressed at rest and decompress it on the fly as you answer
        queries (at least for some very cheap queries)
    -something pointing out we likely have the fastest online
    training/forecasting algorithm in a single CPU thread anyone has published
        -as measured by throughput
        -working name: XFF (eXtremely Fast Forecasting)
    -(?) something about still attaining good compression with a tiny chunk size
        // ^ this is basically a reframing of the low-memory point
        -small chunks -> less read/write amplification
        -when writing many time series concurrently:
            -less need to buffer in order to get compression
                -could compress for low latency and/or real time applications
            -"context switch" between writing to different time series has
            <1KB of overhead, so less cache pressure and probably greater speed
    -(?) something about generalization to arbitrary arrays of fixed-size
    structs (not just time series)


Related work:
    -time series compression
    -integer compression
    -compression for low-power devices?
    -time series databases (we aren't one, but mention them as motivation)?
    -general-purpose compression?
    -other fast forecasting (it's mostly branch predictors that come close)?

Method:
    -Three components:
        1) Forecasting
        2) Bitpacking
        3) Entropy coding

    -1. Forecasting
        -either delta or XFF; XFF is what will take some explaining
        -XFF is linear regression to minimize L1 loss trained via gradient
        descent, but has some subtlety to work on low-bitwidth integer data

    -2. Bitpacking
        -data aggregated into "groups", which contain a fixed number of
        8-element "blocks"
            -"groups" are an optimization to allow vectorization
        -encoding:
            -zigzag encode
            -compute max number of bits to encode any value in each block for
             each variable
            -store all values of that variable in that block using that many bits
            -write the number of bits in the header
            -note that rows are byte-aligned
        -decoding:
            -for each number of bits in the header, expand out the appropriate
            compressed block

        -probably start with explaining low-dimensional case, which is less
        tricky, and then explain how high-dimensional case differs (we pad
        the compressed "rows" to be byte-aligned and vectorize the computations)

    -3. Entropy coding
        -we just run the compressed data through a huffman coder

    -three versions/levels of our algorithm: {low, med, high} compression that
    use subsets of these
        -ah, no, 4 levels: delta, xff, delta+huf, xff+huf


Experiments:
    -compression ratios on UCR datasets   // definitely
        -one CD diagram for sprintz versions vs others
        -one CD diagram for sprintz versions vs delta + others
        -one CD diagram for sprintz versions vs others with low mem (if vs others isn't compelling enough)

    -Decompression speed vs compression ratio
        -compare to other methods directly
            -probably just use level -9 for other methods
        -use various datasets (all our time series datasets?)
        -also do a variation where other methods get delta coding preprocessing
        -maybe just plot methods on the pareto frontier in each ax so it's legible?

        -2 cols; one for 8b, one for 16b
        -row for each dset; dsets = {msrc, pamap, uci_gas, ampd_power}
            -pretty okay just showing the good ampd one as long as we point out the ones where we suck elsewhere

    -decompression speed vs number of cols
        -sprintz-{1,2,3,4} on {4b noise out of 8b, 8b noise out of 16b}
            -and possibly another set of lines for when it's twice as compressible
        -possibly also vary ratio (number of bits in noise)

    -compression speed vs number of cols
        -same setup as above

    -comparison of ours on uint16 data vs {fb gorilla's method, zstd, delta + zstd} on {f32, f64} data?
        -prolly just do this on UCR datasets
        -maybe also include SNR plot here (instead of appendix?)
            -think the SNR plot is actually more important

    -Case studies: show that, for simple statistical queries, our decompression is basically free?
        -sliding mean on 16b?
        -reduce_max on 8b data?
        -should we do both delta and xff here?
        -what data (car accel data?)
        -could classify "ascend stairs" in pamap or "kick" in msrc
            -latter would probably just use a subset of cols...

        -not sure how to sell this because:
            -for cheap queries, we're the bottleneck, so you'd be faster with raw data
            -for expensive queries, decomp isn't the bottleneck, so doesn't matter that we're faster...

            -ah, one insight that might help: we actually can just interleave the ops with the decompression only for us (and not others) because LZ77-based methods *have* to store decompressed data
                -and even LZ78-based methods have to write to their dictionaries
                -so we can boost our speed here a lot and probably come much closer to speed of operating on raw data

            -another difficulty is that, for many actions/queries, we would probably just want a small subset of the columns
                -which both makes coding it harder and removes motivation for using our approach, as opposed to a columnar one

Appendix experiments:

    -effect of group size (parameter that determines size of chunks we compress) on speed
        -with {delta, xff}

    -compression speed, measured in cycles/B, no SIMD instructions
        -since this is what would scale down to a weaker processor
        -synthetic data with various numbers of variables
        -do this as a function of ndims?

    -failure modes of our algorithm
        -ampd_water, ampd_gas

    -loss from quantization (how it's basically nothing)
        -prolly quantize all the UCR time series and do a violinplot with logy
        -mse/variance (wait, is this SNR?)
            -ya, basically (except SNR is log10(variance/mse))
            -https://en.wikipedia.org/wiki/Signal-to-noise_ratio
        -ya, just violinplot quantization SNR for all UCR time series
            -or maybe bar graph with tons of bars?

    -show when the XFF forecasting is useful, since it rarely is on the raw data
        -show that it does way better on timestamps?
        -some experiment where we tune the level of smoothing on some real data?
        -show which UCR datasets (UCR archive is a collection of time series
        datasets) it does better on?

        -EDIT: if xff does better on UCR dsets (which it will), probably don't need this
            -although having some experiment where we progressively smooth stuff and/or explain why it isn't better on the multivariate ts would likely still be good
